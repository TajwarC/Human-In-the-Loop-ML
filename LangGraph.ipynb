{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Zx_mS7r28XJ5",
        "outputId": "4a99deb6-9074-4ba1-ca75-3b313958afe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.34)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.56)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.63-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.16)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Downloading langgraph-0.4.0-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m148.9/148.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.63-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.4.0 langgraph-checkpoint-2.0.25 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.63 ormsgpack-1.9.1 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph langsmith"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ClPXpaSE8ZkA",
        "outputId": "0899e9aa-45da-4b6d-a60d-e20231c6de58"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.23.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.23.1-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, groq, dataclasses-json, langchain_groq, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.23.1 httpx-sse-0.4.0 langchain_community-0.3.23 langchain_groq-0.3.2 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq')\n",
        "langsmith = userdata.get('langsmith')"
      ],
      "metadata": {
        "id": "uIFAYkps8nUH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langsmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"CourseLanggraph\""
      ],
      "metadata": {
        "id": "EnWrAUNI8rzt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "9k8ltNAE-Wri"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(groq_api_key=groq_api_key, model_name = \"Gemma2-9b-It\")\n",
        "\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7KkqwGo-gH0",
        "outputId": "98ac9bde-6a77-45af-ae03-8a1ff0d5d237"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7b664c2fcdd0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7b664c375e50>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start building chatbot with LangGraph"
      ],
      "metadata": {
        "id": "j3Ns0ibJ-vM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "rU6qPo77-oxX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  # Messages have the type \"list\". The 'add_messages\" function in the annotation\n",
        "  # defines how this state key should be updated\n",
        "  # In this case, it appends messages to the list rather than rewriting them\n",
        "  messages:Annotated[list,add_messages]\n",
        "\n",
        "graph_builder = StateGraph(State)"
      ],
      "metadata": {
        "id": "jnZTKt4s_FqE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b3REnfA_mSY",
        "outputId": "7411c121-7423-4f72-969f-6bd5b674735a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b664b660190>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:State):\n",
        "  return {\"messages\": llm.invoke(state['messages'])}"
      ],
      "metadata": {
        "id": "5sSOVQFN_o-U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"chatbot\", chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPsazy8__5O7",
        "outputId": "f011c3b6-d698-40bd-cf0b-b9f17b07c093"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b664b660190>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUawO-d__9TO",
        "outputId": "baa26404-8eb5-4b9e-fbfd-5e0dbda987d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b664b660190>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START,\"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\",END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwShc1ll_-PS",
        "outputId": "46f66c2e-9af4-47a9-fb3c-551cb9b32ce0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7b664b660190>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "xMyru2EoAQOl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"User: \")\n",
        "  if user_input.lower() in [\"quit\", \"q\"]:\n",
        "    print(\"Good Bye\")\n",
        "    break\n",
        "  for event in graph.stream({'messages':(\"user\", user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])\n",
        "      print(\"Assistant:\",value[\"messages\"].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HCk4ulqbASp5",
        "outputId": "c96e49cd-3fdc-4833-b09a-c629aba4faf8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hello\n",
            "dict_values([{'messages': AIMessage(content='Hello! ğŸ‘‹  What can I do for you today?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 11, 'total_tokens': 26, 'completion_time': 0.027272727, 'prompt_time': 0.001920906, 'queue_time': 0.016933414, 'total_time': 0.029193633}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-65b885a9-6052-43da-8501-c94cad6415a8-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26})}])\n",
            "content='Hello! ğŸ‘‹  What can I do for you today?\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 11, 'total_tokens': 26, 'completion_time': 0.027272727, 'prompt_time': 0.001920906, 'queue_time': 0.016933414, 'total_time': 0.029193633}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-65b885a9-6052-43da-8501-c94cad6415a8-0' usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26}\n",
            "Assistant: Hello! ğŸ‘‹  What can I do for you today?\n",
            "\n",
            "User: what is generative AI\n",
            "dict_values([{'messages': AIMessage(content=\"Generative AI refers to a type of artificial intelligence that focuses on creating new content, rather than simply analyzing or classifying existing data. \\n\\nThink of it like this:\\n\\n* **Traditional AI:**  Is good at recognizing patterns and making predictions based on data it's been trained on. For example, it can identify a cat in a picture or predict what you might buy next online.\\n* **Generative AI:**  Learns patterns from data and uses that knowledge to generate new, original content. It can create images, text, music, code, and even 3D models.\\n\\nHere are some key characteristics of generative AI:\\n\\n* **Creativity:** It can produce novel and imaginative outputs that weren't present in the original training data.\\n* **Diversity:** It can generate a wide range of variations within a given style or theme.\\n* **Flexibility:** It can be adapted to generate different types of content by simply changing the input parameters.\\n\\n**Examples of Generative AI:**\\n\\n* **Text generation:** ChatGPT, Bard, Jasper\\n* **Image generation:** DALL-E 2, Stable Diffusion, Midjourney\\n* **Music generation:** Amper Music, Jukebox\\n* **Code generation:** GitHub Copilot\\n\\n**How it works:**\\n\\nGenerative AI models are typically based on deep learning algorithms, particularly a type called **Generative Adversarial Networks (GANs)** or **Transformer networks**. These models are trained on massive datasets of existing content and learn to understand the underlying patterns and structures.\\n\\n**Applications:**\\n\\nGenerative AI has a wide range of potential applications, including:\\n\\n* **Creative industries:** Writing stories, composing music, designing artwork\\n* **Marketing and advertising:** Creating personalized content, generating product descriptions\\n* **Education:** Generating practice problems, creating interactive learning experiences\\n* **Research:** Accelerating scientific discovery by generating new hypotheses and simulations\\n\\n**Ethical considerations:**\\n\\nThe rise of generative AI also raises ethical concerns, such as:\\n\\n* **Misinformation:** The ability to generate realistic fake content can be used for malicious purposes.\\n* **Bias:** AI models can inherit and amplify biases present in the training data.\\n* **Copyright:** The ownership and copyright of AI-generated content is a complex issue.\\n\\n\\nIt's an exciting field with the potential to revolutionize many industries, but it's important to approach it responsibly and address the ethical challenges it presents.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 499, 'prompt_tokens': 13, 'total_tokens': 512, 'completion_time': 0.907272727, 'prompt_time': 0.001928967, 'queue_time': 0.017341712999999998, 'total_time': 0.909201694}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-74d49b96-4c64-40d1-af31-7eb1786f0e75-0', usage_metadata={'input_tokens': 13, 'output_tokens': 499, 'total_tokens': 512})}])\n",
            "content=\"Generative AI refers to a type of artificial intelligence that focuses on creating new content, rather than simply analyzing or classifying existing data. \\n\\nThink of it like this:\\n\\n* **Traditional AI:**  Is good at recognizing patterns and making predictions based on data it's been trained on. For example, it can identify a cat in a picture or predict what you might buy next online.\\n* **Generative AI:**  Learns patterns from data and uses that knowledge to generate new, original content. It can create images, text, music, code, and even 3D models.\\n\\nHere are some key characteristics of generative AI:\\n\\n* **Creativity:** It can produce novel and imaginative outputs that weren't present in the original training data.\\n* **Diversity:** It can generate a wide range of variations within a given style or theme.\\n* **Flexibility:** It can be adapted to generate different types of content by simply changing the input parameters.\\n\\n**Examples of Generative AI:**\\n\\n* **Text generation:** ChatGPT, Bard, Jasper\\n* **Image generation:** DALL-E 2, Stable Diffusion, Midjourney\\n* **Music generation:** Amper Music, Jukebox\\n* **Code generation:** GitHub Copilot\\n\\n**How it works:**\\n\\nGenerative AI models are typically based on deep learning algorithms, particularly a type called **Generative Adversarial Networks (GANs)** or **Transformer networks**. These models are trained on massive datasets of existing content and learn to understand the underlying patterns and structures.\\n\\n**Applications:**\\n\\nGenerative AI has a wide range of potential applications, including:\\n\\n* **Creative industries:** Writing stories, composing music, designing artwork\\n* **Marketing and advertising:** Creating personalized content, generating product descriptions\\n* **Education:** Generating practice problems, creating interactive learning experiences\\n* **Research:** Accelerating scientific discovery by generating new hypotheses and simulations\\n\\n**Ethical considerations:**\\n\\nThe rise of generative AI also raises ethical concerns, such as:\\n\\n* **Misinformation:** The ability to generate realistic fake content can be used for malicious purposes.\\n* **Bias:** AI models can inherit and amplify biases present in the training data.\\n* **Copyright:** The ownership and copyright of AI-generated content is a complex issue.\\n\\n\\nIt's an exciting field with the potential to revolutionize many industries, but it's important to approach it responsibly and address the ethical challenges it presents.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 499, 'prompt_tokens': 13, 'total_tokens': 512, 'completion_time': 0.907272727, 'prompt_time': 0.001928967, 'queue_time': 0.017341712999999998, 'total_time': 0.909201694}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-74d49b96-4c64-40d1-af31-7eb1786f0e75-0' usage_metadata={'input_tokens': 13, 'output_tokens': 499, 'total_tokens': 512}\n",
            "Assistant: Generative AI refers to a type of artificial intelligence that focuses on creating new content, rather than simply analyzing or classifying existing data. \n",
            "\n",
            "Think of it like this:\n",
            "\n",
            "* **Traditional AI:**  Is good at recognizing patterns and making predictions based on data it's been trained on. For example, it can identify a cat in a picture or predict what you might buy next online.\n",
            "* **Generative AI:**  Learns patterns from data and uses that knowledge to generate new, original content. It can create images, text, music, code, and even 3D models.\n",
            "\n",
            "Here are some key characteristics of generative AI:\n",
            "\n",
            "* **Creativity:** It can produce novel and imaginative outputs that weren't present in the original training data.\n",
            "* **Diversity:** It can generate a wide range of variations within a given style or theme.\n",
            "* **Flexibility:** It can be adapted to generate different types of content by simply changing the input parameters.\n",
            "\n",
            "**Examples of Generative AI:**\n",
            "\n",
            "* **Text generation:** ChatGPT, Bard, Jasper\n",
            "* **Image generation:** DALL-E 2, Stable Diffusion, Midjourney\n",
            "* **Music generation:** Amper Music, Jukebox\n",
            "* **Code generation:** GitHub Copilot\n",
            "\n",
            "**How it works:**\n",
            "\n",
            "Generative AI models are typically based on deep learning algorithms, particularly a type called **Generative Adversarial Networks (GANs)** or **Transformer networks**. These models are trained on massive datasets of existing content and learn to understand the underlying patterns and structures.\n",
            "\n",
            "**Applications:**\n",
            "\n",
            "Generative AI has a wide range of potential applications, including:\n",
            "\n",
            "* **Creative industries:** Writing stories, composing music, designing artwork\n",
            "* **Marketing and advertising:** Creating personalized content, generating product descriptions\n",
            "* **Education:** Generating practice problems, creating interactive learning experiences\n",
            "* **Research:** Accelerating scientific discovery by generating new hypotheses and simulations\n",
            "\n",
            "**Ethical considerations:**\n",
            "\n",
            "The rise of generative AI also raises ethical concerns, such as:\n",
            "\n",
            "* **Misinformation:** The ability to generate realistic fake content can be used for malicious purposes.\n",
            "* **Bias:** AI models can inherit and amplify biases present in the training data.\n",
            "* **Copyright:** The ownership and copyright of AI-generated content is a complex issue.\n",
            "\n",
            "\n",
            "It's an exciting field with the potential to revolutionize many industries, but it's important to approach it responsibly and address the ethical challenges it presents.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b48d0910f664>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"q\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Good Bye\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0z_WGhgoBFTS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}